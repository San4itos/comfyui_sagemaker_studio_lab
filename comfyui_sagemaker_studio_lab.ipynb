{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Check Information (Debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking Folders Sizes\n",
    "!du -h -d1\n",
    "\n",
    "# Check torch version\n",
    "%pip list -v | grep torch\n",
    "\n",
    "# Check working directory\n",
    "!echo \"Working directrory:\"\n",
    "%pwd\n",
    "!du -sh $(pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Update torch to latest version (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install --root-user-action=ignore --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaaaaaaaaa"
   },
   "source": [
    "# 1. Install ComfyUI and dependencies\n",
    "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbbbbbbbbb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Environment Setup\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "OPTIONS = {}\n",
    "\n",
    "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
    "USE_COMFYUI_MANAGER = True  #@param {type:\"boolean\"}\n",
    "\n",
    "WORKSPACE = 'ComfyUI'\n",
    "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
    "OPTIONS['USE_COMFYUI_MANAGER'] = USE_COMFYUI_MANAGER\n",
    "\n",
    "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
    "%cd $WORKSPACE\n",
    "\n",
    "if OPTIONS['UPDATE_COMFY_UI']:\n",
    "  !echo -= Updating ComfyUI =-\n",
    "  !git pull\n",
    "\n",
    "if OPTIONS['USE_COMFYUI_MANAGER']:\n",
    "  %cd custom_nodes\n",
    "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
    "  %cd ComfyUI-Manager\n",
    "  !echo -= Updating ComfyUI Manager =-\n",
    "  !git pull\n",
    "  %cd ../..\n",
    "\n",
    "!echo -= Install dependencies =-\n",
    "%pip install torch torchvision torchaudio\n",
    "%pip install -r requirements.txt\n",
    "%pip install pyngrok\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cccccccccc"
   },
   "source": [
    "#### 1.1. Download some models/checkpoints/vae or custom comfyui nodes \n",
    "(uncomment the commands for the ones you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_url = [\n",
    "\n",
    "    # Download models into folders. Uncomment necessary links.\n",
    "    # Format: (\"URL\",\"PATH\",\"*NAME (optional)\"),\n",
    "\n",
    "    # Checkpoints\n",
    "\n",
    "### Preview Models\n",
    "    # (\"https://github.com/madebyollin/taesd/raw/main/taesd_decoder.pth\", \"./models/vae_approx/\"),\n",
    "    # (\"https://github.com/madebyollin/taesd/raw/main/taesdxl_decoder.pth\", \"./models/vae_approx/\"),\n",
    "    # (\"https://github.com/madebyollin/taesd/raw/main/taesd_decoder.pth\", \"./models/vae_approx/\"),\n",
    "    # (\"https://github.com/madebyollin/taesd/raw/main/taesdxl_decoder.pth\", \"./models/vae_approx/\"),\n",
    "\n",
    "### SDXL\n",
    "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
    "\n",
    "    # (\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0_0.9vae.safetensors\", \"./models/checkpoints/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0_0.9vae.safetensors\", \"./models/checkpoints/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\", \"./models/checkpoints/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors\", \"./models/checkpoints/\"),\n",
    "\n",
    "# SDXL ReVision\n",
    "    # (\"https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors\", \"./models/clip_vision/\"),\n",
    "\n",
    "# SD1.5\n",
    "    # (\"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \"./models/checkpoints/\"),\n",
    "\n",
    "# SD2\n",
    "    # (\"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors\", \"./models/checkpoints/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\", \"./models/checkpoints/\"),\n",
    "\n",
    "# Some SD1.5 anime style\n",
    "    # (\"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors\", \"./models/checkpoints/\"),\n",
    "    # (\"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors\", \"./models/checkpoints/\"),\n",
    "    # (\"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors\", \"./models/checkpoints/\"),\n",
    "    # (\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors\", \"./models/checkpoints/\"),\n",
    "\n",
    "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
    "    # (\"https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors\", \"./models/checkpoints/\"),\n",
    "\n",
    "\n",
    "# unCLIP models\n",
    "    # (\"https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors\", \"./models/checkpoints/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors\", \"./models/checkpoints/\"),\n",
    "\n",
    "\n",
    "# VAE\n",
    "    # (\"https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.safetensors\", \"./models/vae/\", \"sd-vae-ft-mse.safetensors\"),\n",
    "    # (\"https://huggingface.co/stabilityai/sd-vae-ft-ema/resolve/main/diffusion_pytorch_model.safetensors\", \"./models/vae/\", \"sd-vae-ft-ema.safetensors\"),\n",
    "    # (\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\", \"./models/vae/\"),\n",
    "    # (\"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt\", \"./models/vae/\"),\n",
    "    # (\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\", \"./models/vae/\"),\n",
    "# SDXL VAE\n",
    "    # (\"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\", \"./models/vae/\"),\n",
    "\n",
    "# IP-Adapter (downloading to 'ComfyUI_IPAdapter_plus' node folder)\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus-face_sd15.bin\", \"./custom_nodes/ComfyUI_IPAdapter_plus/models\"),\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter-plus_sd15.bin\", \"./custom_nodes/ComfyUI_IPAdapter_plus/models\"),\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15.bin\", \"./custom_nodes/ComfyUI_IPAdapter_plus/models\"),\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/models/ip-adapter_sd15_light.bin\", \"./custom_nodes/ComfyUI_IPAdapter_plus/models\"),\n",
    "# IP-Adapter SDXL\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter-plus_sdxl_vit-h.bin\", \"\"),\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl.bin\", \"\"),\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/ip-adapter_sdxl_vit-h.bin\", \"\"),\n",
    "# Image Encoder (for IP-Adapter)\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/models/image_encoder/model.safetensors\", \"./models/clip_vision/\", \"image_encoder_model.safetensors\"),\n",
    "# Image Encoder SDXL (for IP-Adapter)\n",
    "    # (\"https://huggingface.co/h94/IP-Adapter/resolve/main/sdxl_models/image_encoder/model.safetensors\", \"./models/clip_vision/\", \"image_encoder_sdxl_model.safetensors\"),\n",
    "       \n",
    "    \n",
    "# Loras\n",
    "    # (\"https://civitai.com/api/download/models/10350\", \"./models/loras/\", \"theovercomer8sContrastFix_sd21768.safetensors\"), #theovercomer8sContrastFix SD2.x 768-v\n",
    "    # (\"https://civitai.com/api/download/models/10638\", \"./models/loras/\", \"theovercomer8sContrastFix_sd15.safetensors\"), #theovercomer8sContrastFix SD1.x\n",
    "    # (\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/\", \"./models/loras/\", \"sd_xl_offset_example-lora_1.0.safetensors\"), #SDXL offset noise lora\n",
    "\n",
    "\n",
    "# T2I-Adapter\n",
    "    # (\"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth\", \"./models/controlnet/\"),\n",
    "\n",
    "# T2I-Adapter SDXL\n",
    "    # (\"https://huggingface.co/TencentARC/t2i-adapter-canny-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors\", \"./models/controlnet/\", \"t2i-adapter-canny-sdxl-1.0.safetensors\"),\n",
    "    # (\"https://huggingface.co/TencentARC/t2i-adapter-sketch-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors\", \"./models/controlnet/\", \"t2i-adapter-sketch-sdxl-1.0.safetensors\"),\n",
    "    # (\"https://huggingface.co/TencentARC/t2i-adapter-openpose-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors\", \"./models/controlnet/\", \"t2i-adapter-openpose-sdxl-1.0.safetensors\"),\n",
    "    # (\"https://huggingface.co/TencentARC/t2i-adapter-lineart-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors\", \"./models/controlnet/\", \"t2i-adapter-lineart-sdxl-1.0.safetensors\"),\n",
    "    # (\"https://huggingface.co/TencentARC/t2i-adapter-depth-midas-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors\", \"./models/controlnet/\", \"t2i-adapter-depth-midas-sdxl-1.0.safetensors\"),\n",
    "    # (\"https://huggingface.co/TencentARC/t2i-adapter-depth-zoe-sdxl-1.0/resolve/main/diffusion_pytorch_model.safetensors\", \"./models/controlnet/\", \"t2i-adapter-depth-zoe-sdxl-1.0.safetensors\"),\n",
    "\n",
    "# T2I Styles Model\n",
    "    # (\"https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth\", \"./models/style_models/\"),\n",
    "\n",
    "# CLIPVision model (needed for styles model)\n",
    "    # (\"https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin\", \"./models/clip_vision/\", \"clip_vit14.bin\"),\n",
    "\n",
    "\n",
    "# Control-lora stabilityai\n",
    "    # (\"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank128/control-lora-canny-rank128.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank128/control-lora-depth-rank128.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank128/control-lora-recolor-rank128.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank128/control-lora-sketch-rank128-metadata.safetensors\", \"./models/controlnet/\"),\n",
    "\n",
    "# ControlNet\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors\", \"./models/controlnet/\"),\n",
    "\n",
    "# ControlNet SDXL\n",
    "    # (\"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors\", \"./models/controlnet/\"),\n",
    "    # (\"https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors\", \"./models/controlnet/\"),\n",
    "\n",
    "# GLIGEN\n",
    "    # (\"https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors\", \"./models/gligen/\"),\n",
    "\n",
    "# ESRGAN upscale model\n",
    "    # (\"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\", \"./models/upscale_models/\"),\n",
    "    # (\"https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth\", \"./models/upscale_models/\"),\n",
    "    # (\"https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth\", \"./models/upscale_models/\"),\n",
    "]\n",
    "\n",
    "# Controlnet Preprocessor nodes by Fannovel16\n",
    "#%cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
    "\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "for _, model in enumerate(model_url):\n",
    "    model_url = model[0]\n",
    "    model_path = model[1]\n",
    "    model_name = model_url.split(\"/\")[-1]\n",
    "    \n",
    "    if len(model) > 2:\n",
    "        model_name = model[2]\n",
    "    try:\n",
    "       response = requests.get(model_url, stream=True)\n",
    "    except:\n",
    "       print(\"Unknown error.\")\n",
    "\n",
    "    if not model_name:\n",
    "        if 'content-disposition' in response.headers:\n",
    "            d = response.headers['content-disposition']\n",
    "            model_name = re.findall(\"filename=(.+)\", d)[0].strip(\"\\\"';\")\n",
    "    \n",
    "    file_path = os.path.join(model_path, model_name)\n",
    "    \n",
    "\n",
    "    print(f\"Downloading now: {model_name} to {model_path}\")\n",
    "    total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024 #1 Kibibyte\n",
    "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "    progress_bar.close()\n",
    "\n",
    "    if total_size_in_bytes and progress_bar.n != total_size_in_bytes:\n",
    "        print(f\"ERROR downloading {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkkkkkkkkkkkkk",
    "tags": []
   },
   "source": [
    "### 2. Run ComfyUI\n",
    "Don't forget to fill your [***ngrok token***](https://dashboard.ngrok.com/get-started/your-authtoken) or ***studiolab url*** address\n",
    "*`example: (https://abcdefghijkl123.studio.us-east-2.sagemaker.aws)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjjjjjjjjjjjj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# put your Ngrok token here\n",
    "ngrok_token=\"\"\n",
    "\n",
    "# put your SageMaker Studio lab url adress here\n",
    "sage_url = \"\"\n",
    "\n",
    "# Put ComfyUI command line args here\n",
    "args = \"--preview-method auto --enable-cors-header --use-pytorch-cross-attention\"\n",
    "\n",
    "\n",
    "from threading import Timer\n",
    "from queue import Queue\n",
    "from pyngrok import ngrok\n",
    "import os\n",
    "\n",
    "def ngrok_tunnel(port,queue,auth_token):\n",
    "    ngrok.set_auth_token(auth_token)\n",
    "    url = ngrok.connect(port)\n",
    "    queue.put(url)\n",
    "    \n",
    "def launch_comfy(ngrok_token, url_adress, args):\n",
    "    if ngrok_token:\n",
    "        ngrok_output_queue = Queue()\n",
    "        ngrok_thread = Timer(2, ngrok_tunnel, args=(8188, ngrok_output_queue, ngrok_token))\n",
    "        ngrok_thread.start()\n",
    "        ngrok_thread.join()\n",
    "        print(ngrok_output_queue.get())\n",
    "    elif url_adress:\n",
    "        print(f'Wait for local URL to appear, then use this link:')\n",
    "        print(f'{sage_url}/studiolab/default/jupyter/proxy/8188/\\n')\n",
    "    else:\n",
    "        print(f\"-= Please fill your ngrok token or studiolab url address =-\\nExiting...\")\n",
    "        return\n",
    "    os.system(\"python main.py \" + args)\n",
    "    \n",
    "launch_comfy(ngrok_token, sage_url, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
